{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pca-color-augment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "18rBGTt1wGYQzfJoMX6VAWc1Wjz6IwjMT",
      "authorship_tag": "ABX9TyNe6Bczn9OKBZhn2yX6iw2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/addieira03/pca-color-augment/blob/master/pca_color_augment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPBn_498wwoT",
        "colab_type": "text"
      },
      "source": [
        "# **What is PCA Color Augmentation?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4s2RoieyuDZ",
        "colab_type": "text"
      },
      "source": [
        "Data augmentation is the artificial enlargment of the dataset to reduce overfitting on the image data during training. The easiest and most common method to perform data augmentation is to use transformations that preserve the labels. One example is **PCA Color Augmentation**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxZnmJ6MxZQR",
        "colab_type": "text"
      },
      "source": [
        "PCA Color Augmentation (also called **Fancy PCA**) alters the intensities of the RGB channels along the natural variations of the images, denoted by the principal components of the pixel colors (Bargoti & Underwood, 2016). It performs Principal Components Analysis on the color channels, thus, given the name *Fancy PCA*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bJaZhb3zkrb",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://pixelatedbrian.github.io/img/fancy_pca/fancy_pca.png)\n",
        "\n",
        "(Image Source: https://pixelatedbrian.github.io/2018-04-29-fancy_pca/)\n",
        "\n",
        "\n",
        "The figure above shows an example of how Fancy PCA looks very natural compared to random changes in the RGB intensities. To make the intensity change more obvious to the naked eye, augmentation in this example was magnified by ~1000x. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUL2HwW8pSB3",
        "colab_type": "text"
      },
      "source": [
        "## **\"What do I need to know before learning Fancy PCA?\"**\n",
        "\n",
        "If you have a good foundation in linear algebra, you will be able to fully grasp the algorithm of fancy PCA. \n",
        "\n",
        "If you are a beginner both to linear algebra and fancy PCA, here's a [playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab) of Youtube videos to teach you about the fundamentals of linear algebra. \n",
        "\n",
        "After that, read about principal component analysis (PCA). Or you can watch this [step-by-step video](https://www.youtube.com/watch?v=FgakZw6K1QQ) about PCA. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvaczR1JWdIb",
        "colab_type": "text"
      },
      "source": [
        "## **How Fancy PCA works**\n",
        "\n",
        "This method is based on the study by *Krizhevsky, Sutskever & Hinton (2012)*, the proponents of AlexNet. \n",
        "\n",
        "Specifically, Principal Component Analysis is performed on the set of RGB pixel values *throughout the image dataset*. To each image, multiples of the found principal components are added, with magnitudes proportional to the corresponding eigenvalues times a random variable drawn from a Gaussian distribution with mean=0 and standard deviation=0.1.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jub2jdaubhNt",
        "colab_type": "text"
      },
      "source": [
        "Therefore to each RGB image pixel $I_{xy}= [I_{xy}^R,I_{xy}^G,I_{xy}^B]^T$ the following quantity is added:\n",
        "\n",
        "$[p_1,p_2,p_3][\\alpha_1\\lambda_1,\\alpha_2\\lambda_2,\\alpha_3\\lambda_3]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTW8S8aPeY9j",
        "colab_type": "text"
      },
      "source": [
        "where $p_1$ and $\\lambda_i$ are $i$th eigenvector and eigenvalue of the 3 Ã— 3 covariance matrix of RGB pixel values, respectively, and $\\alpha_i$ is the aforementioned random variable. Each $\\alpha_i$ is drawn only once for all the pixels of a particular training image until that image is used for training again, at which point it is re-drawn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG4g--yK9idf",
        "colab_type": "text"
      },
      "source": [
        "## **Step-by-step algorithm of Fancy PCA**\n",
        "\n",
        "This algorithm is mainly based on this [Python code](https://github.com/pixelatedbrian/fortnight-furniture/blob/master/src/fancy_pca.py) for Fancy PCA (with few modifications). I used numpy and PIL libraries. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZs5TvaF8Qp_",
        "colab_type": "text"
      },
      "source": [
        "**Step 1.** Load the image(s) as a numpy array with (h, w, rgb) shape as integers between 0 to 255\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "\n",
        "im = Image.open('image.jpg') #load image.jpg\n",
        "i_a = asarray(im) #convert image to array\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-0ya65LQjqI",
        "colab_type": "text"
      },
      "source": [
        "**Step 2.** Convert the range of pixel values from 0-255 to 0-1 \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "i_a = i_a / 255.0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwdxORSxTTzg",
        "colab_type": "text"
      },
      "source": [
        "**Step 3.** Flatten the image to columns of RGB (3 columns)\n",
        "\n",
        "Flattening the images merges all the layers (in this case, RGB layers) into one column each color channel.\n",
        "\n",
        "\n",
        "```\n",
        "img_rs = i_a.reshape(-1, 3)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rmVEB6NgdN7",
        "colab_type": "text"
      },
      "source": [
        "**Step 4.** Centering the pixels around their mean (for more info, [click here](https://en.wikipedia.org/wiki/Principal_component_analysis#/media/File:GaussianScatterPCA.svg))\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "img_centered = img_rs - np.mean(img_rs, axis=0)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJp2DfnIge9h",
        "colab_type": "text"
      },
      "source": [
        "**Step 5.** Calculate the 3x3 covariance matrix using [numpy.cov](https://numpy.org/doc/stable/reference/generated/numpy.cov.html). The parameter `rowvar` is set as `False` because each column represents a variable, while rows contain the values.\n",
        "\n",
        "\n",
        "```\n",
        "img_cov = np.cov(img_centered, rowvar=False)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKOIqUS3ggo-",
        "colab_type": "text"
      },
      "source": [
        "**Step 6.** Calculate the *eigenvalues* (3x1 matrix) and *eigenvectors* (3x3 matrix) of the 3 x3 covariance matrix using [numpy.linalg.eigh](https://numpy.org/doc/stable/reference/generated/numpy.linalg.eigh.html)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "eig_vals, eig_vecs = np.linalg.eigh(img_cov)\n",
        "```\n",
        "\n",
        "Then, sort the eigenvalues and eigenvectors\n",
        "\n",
        "```\n",
        "sort_perm = eig_vals[::-1].argsort()\n",
        "eig_vals[::-1].sort()\n",
        "eig_vecs = eig_vecs[:, sort_perm]\n",
        "```\n",
        "\n",
        "After that, you will finally get eigenvector matrix [p1, p2, p3]  as:\n",
        "\n",
        "\n",
        "```\n",
        "m1 = np.column_stack((eig_vecs))\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj0RY3pLgnUy",
        "colab_type": "text"
      },
      "source": [
        "**Step 7.** Get a 3x1 matrix of eigenvalues multipled by a *random variable* drawn from a Gaussian distribution with mean=0 and sd=0.1 using [numpy.random.normal](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)\n",
        "\n",
        "\n",
        "One thing to note, according to Krizhevsky, Sutskever & Hinton (2012), is that the alpha should only be drawn once per augmentation (not once per channel)\n",
        "\n",
        "```\n",
        "m2 = np.zeros((3, 1))\n",
        "alpha = np.random.normal(0, 0.1)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlPkhtdogp4o",
        "colab_type": "text"
      },
      "source": [
        "**Step 8.** Create and add the vector (add_vect) that we're going to add to each pixel\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "m2[:, 0] = alpha * eig_vals[:]\n",
        "add_vect = np.matrix(m1) * np.matrix(m2)\n",
        "\n",
        "for idx in range(3):   # RGB\n",
        "    orig_img[..., idx] += add_vect[idx]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dojd3beplrBR",
        "colab_type": "text"
      },
      "source": [
        "**Step 9.** Convert the range of arrays from 0-1 to 0-255 (u-int8)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "orig_img = np.clip(orig_img, 0.0, 255.0)\n",
        "orig_img = orig_img.astype(np.uint8)\n",
        "\n",
        "return orig_img\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmQ2eUokl72y",
        "colab_type": "text"
      },
      "source": [
        "**Step 10.** Convert the array of the augmented image back to jpg using [Image.fromarray](https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.fromarray)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "final_img = Image.fromarray(orig_img)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyEbN0NM98qJ",
        "colab_type": "text"
      },
      "source": [
        "## **Fancy PCA on batch of images**\n",
        "\n",
        "The code below is to perform fancy PCA to a batch of images in a folder to another destination folder. Try editing `path, path2` and `path3` to test your own image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELGHLa1h8J5O",
        "colab_type": "code",
        "outputId": "ebfb56ca-01d0-4ae4-bd2e-ea6fb23817cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Import required libraries\n",
        "from numpy import asarray\n",
        "import argparse\n",
        "import fancy_pca\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load multiple images\n",
        "image_list = []\n",
        "fname_list = []\n",
        "path = '/content/drive/My Drive/images/orig/lori.jpg' # path of the original image dataset. \n",
        "path2 = '/content/drive/My Drive/images/orig/' # path of the original dataset folder\n",
        "\n",
        "# Load images and put them in a list (image_list)\n",
        "for infile in glob.glob(path):\n",
        "    im = Image.open(infile)\n",
        "    image_list.append(im)\n",
        "\n",
        "# Extract the names of the files and put them in a list (fname_list)\n",
        "base = os.listdir(path2)\n",
        "for f in base:\n",
        "    fname = os.path.splitext(f)\n",
        "    fname_list.append(fname[0])\n",
        "    print(\"Loading\",infile)\n",
        "    print(len(image_list),\" images has loaded.\")\n",
        "\n",
        "\n",
        "# Convert images to numpy arrays\n",
        "array_list =[]\n",
        "n=1\n",
        "for i in image_list:\n",
        "    i_a = asarray(i)\n",
        "    array_list.append(i_a)\n",
        "    print(\"Image\", n, \": Conversion successful.\")\n",
        "    n+=1\n",
        "print(\"Array of original image: \", i_a) #To see the array\n",
        "\n",
        "print(\"Conversion successful\")\n",
        "print(type(i_a), i_a.shape)\n",
        "\n",
        "# Perform the PCA color augmentation\n",
        "n=1\n",
        "aug_list=[]\n",
        "for a in array_list:\n",
        "    augmented = fancy_pca.fancy_pca(a)\n",
        "    aug_list.append(a)\n",
        "    print(\"Array\",n, \":Augmentation successful\")\n",
        "    n += 1\n",
        "print(\"Array of PCA augmented image: \", augmented) #To see the array\n",
        "\n",
        "# Convert Fancy PCA result back to PIL image\n",
        "path3 = \"/content/drive/My Drive/images/aug/\" #path of the destination folder\n",
        "idx=0\n",
        "for aug in aug_list:\n",
        "    i2 = Image.fromarray(aug)\n",
        "    print(fname_list)\n",
        "    while idx<= len(fname_list):\n",
        "        print(str(fname_list[idx])+\"_1.jpg\")\n",
        "        i2.save(path3+(str(fname_list[idx])+\"_1.jpg\"))\n",
        "        break\n",
        "    idx+=1\n",
        "    print(\"Augmented image\", idx, \"saved.\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading /content/drive/My Drive/images/orig/lori.jpg\n",
            "1  images has loaded.\n",
            "Image 1 : Conversion successful.\n",
            "Array of original image:  [[[136  99  31]\n",
            "  [158 123  59]\n",
            "  [160 128  71]\n",
            "  ...\n",
            "  [178 130  92]\n",
            "  [171 123  87]\n",
            "  [165 119  85]]\n",
            "\n",
            " [[161 124  56]\n",
            "  [137 103  39]\n",
            "  [134 103  46]\n",
            "  ...\n",
            "  [182 134  96]\n",
            "  [173 127  91]\n",
            "  [169 123  89]]\n",
            "\n",
            " [[156 123  56]\n",
            "  [117  86  22]\n",
            "  [125  99  42]\n",
            "  ...\n",
            "  [187 139 101]\n",
            "  [178 132  96]\n",
            "  [171 127  92]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[138 126  26]\n",
            "  [140 127  25]\n",
            "  [147 134  32]\n",
            "  ...\n",
            "  [137 168  51]\n",
            "  [134 168  48]\n",
            "  [133 167  46]]\n",
            "\n",
            " [[121 109  11]\n",
            "  [130 118  18]\n",
            "  [143 131  31]\n",
            "  ...\n",
            "  [136 170  50]\n",
            "  [135 169  48]\n",
            "  [134 168  47]]\n",
            "\n",
            " [[126 116  18]\n",
            "  [137 127  29]\n",
            "  [149 140  39]\n",
            "  ...\n",
            "  [136 170  49]\n",
            "  [134 170  48]\n",
            "  [134 170  46]]]\n",
            "Conversion successful\n",
            "<class 'numpy.ndarray'> (607, 910, 3)\n",
            "Array 1 :Augmentation successful\n",
            "Array of PCA augmented image:  [[[135  99  30]\n",
            "  [157 123  58]\n",
            "  [159 128  70]\n",
            "  ...\n",
            "  [177 130  91]\n",
            "  [170 123  86]\n",
            "  [164 119  84]]\n",
            "\n",
            " [[160 124  55]\n",
            "  [136 103  38]\n",
            "  [133 103  45]\n",
            "  ...\n",
            "  [181 134  95]\n",
            "  [172 127  90]\n",
            "  [168 123  88]]\n",
            "\n",
            " [[155 123  55]\n",
            "  [116  86  21]\n",
            "  [124  99  41]\n",
            "  ...\n",
            "  [186 139 100]\n",
            "  [177 132  95]\n",
            "  [170 127  91]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[137 126  25]\n",
            "  [139 127  24]\n",
            "  [146 134  31]\n",
            "  ...\n",
            "  [136 168  50]\n",
            "  [133 168  47]\n",
            "  [132 167  45]]\n",
            "\n",
            " [[120 109  10]\n",
            "  [129 118  17]\n",
            "  [142 131  30]\n",
            "  ...\n",
            "  [135 170  49]\n",
            "  [134 169  47]\n",
            "  [133 168  46]]\n",
            "\n",
            " [[125 116  17]\n",
            "  [136 127  28]\n",
            "  [148 140  38]\n",
            "  ...\n",
            "  [135 170  48]\n",
            "  [133 170  47]\n",
            "  [133 170  45]]]\n",
            "['lori']\n",
            "lori_1.jpg\n",
            "Augmented image 1 saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSMqwW5a0JOI",
        "colab_type": "text"
      },
      "source": [
        "## **Literature Cited**\n",
        "\n",
        "\n",
        "1.   Bargoti, S., Underwood, J. (2016). Deep Fruit Detection in Orchards. Proceedings - IEEE International Conference on Robotics and Automation, 3626â€“3633. https://doi.org/10.1109/ICRA.2017.7989417\n",
        "2.   Krizhevsky, A., Sutskever, I., Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. In F. Pereira, C. J. C. Burges, L. Bottou, & K. Q. Weinberger (Eds.), Advances in neural information processing systems 25 (pp. 1097â€“1105). Curran Associates, Inc. Retrieved from https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
        "\n"
      ]
    }
  ]
}